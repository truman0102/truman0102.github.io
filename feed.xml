<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://truman0102.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://truman0102.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-14T09:30:49+00:00</updated><id>https://truman0102.github.io/feed.xml</id><title type="html">Hongguang</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Learning Steiner Tree for Overflow-avoiding Global Routing in Chip Design</title><link href="https://truman0102.github.io/blog/2024/neuralsteiner/" rel="alternate" type="text/html" title="Learning Steiner Tree for Overflow-avoiding Global Routing in Chip Design"/><published>2024-12-11T06:00:00+00:00</published><updated>2024-12-11T06:00:00+00:00</updated><id>https://truman0102.github.io/blog/2024/neuralsteiner</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/neuralsteiner/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>全局路由问题是构建一棵连接所有引脚的直角树，一般用Hanan网格或逃逸图来生成避障最短路径RSMT，在大规模集成电路上一般很难优化拥塞问题。</p> <p>在最小生成树中有必要考虑边的容量，定义边\(e(u,v)\in E\)的容量为\(c(u, v)\)，\(d(u, v)\)表示通过\(e(u, v)\)的路由的数量，\(r(u,v)=c(u,v)-d(u,v)\)是边的可用资源，理想情况下我们应当维持\(r\geq 0\)，不然就会导致溢出 (overflow) 问题。</p> <p>基于学习的路由方法生成路由结果构建最短斯坦纳树，但事实上有时一个路径长度次优的路由结果可以减少拥塞或者减少溢出的可能性。</p> <h2 id="methodology">Methodology</h2> <h3 id="grouped-parallel">Grouped Parallel</h3> <h3 id="point-prediction">Point Prediction</h3> <p>点预测被理解为一个像素级分类问题，识别潜在的Steiner点。与HubRouter工作一样使用了CUGR方法在benchmark上构建专家路由结果，应用其逻辑斯蒂函数计算溢出值，得到减小拥塞的路由结果，并选出可参考的Steiner点。</p> <p>网络结构是ResNet + recurrent crisscross attention mechanism (RCCA)</p> <p>目标函数有三个部分，前两个目标函数针对点预测问题，第三个目标函数针对溢出问题</p> <ol> <li>focal loss:\(-\alpha(1-p_t)^\gamma\log(p_t)\)</li> <li>dice loss: \(1-\frac{2\sum p_{xy}g_{xy}+\epsilon}{\sum p_{xy} + \sum g_{xy} + \epsilon}\)</li> <li>overflow loss: \(\frac{\sum p_{xy}o_{xy}+\epsilon}{\sum p_{xy}+\epsilon}\)</li> </ol> <h3 id="net-augmented-graph">Net Augmented Graph</h3> <p>将pin grid和point grid合并可以得到一个潜在连接点网格，将网格中有值的点（pin或者Steiner点）连接起来，得到一个Net Augmented Graph。边的选择规则如下</p> <ol> <li>两个point在水平或垂直方向上一致</li> <li>两点中间没有其他点</li> </ol> <p>边的权重计算方式为</p> \[\mathcal{W}(e) = w_d(\vert x_p - x_q \vert + \vert y_p - y_q \vert) + w_o\sum o_{xy}\] <p>这个权重函数包含了两个部分，一个是两点之间的曼哈顿距离，另一个是两点之间的溢出值。</p> <h3 id="rst-construction">RST Construction</h3> <p>依据pin之间的连通性，芯片上的pin被分成多个group，每次迭代都计算group之间的距离，然后对group贪心地合并，即每次合并两个最近的group，然后更新距离，直到只剩下一个group。这其实是一种层次化的聚类方法。</p> <h2 id="experiment">Experiment</h2> <p>Benchmark 包括 ISPD98/07/18/19</p>]]></content><author><name></name></author><category term="paper-reading"/><category term="chip"/><category term="RL"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Reinforcement Learning within Tree Search for Fast Macro Placement</title><link href="https://truman0102.github.io/blog/2024/efficient-place/" rel="alternate" type="text/html" title="Reinforcement Learning within Tree Search for Fast Macro Placement"/><published>2024-12-11T05:00:00+00:00</published><updated>2024-12-11T05:00:00+00:00</updated><id>https://truman0102.github.io/blog/2024/efficient-place</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/efficient-place/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>全局树搜索+局部策略学习：在更高层次上，蒙特卡洛树搜索（MCTS）被用来对搜索过程进行战略性导航。它利用一种新颖的滚动边界（frontier）机制，引导代理关注和利用有价值的状态，从而加强对精英解决方案的优化。下层利用 RL 代理的学习和概括能力，促进在广阔的搜索空间中进行高效探索。这种双层框架产生了一种动态协同效应：MCTS 引导的直接优化和 RL 驱动的自适应学习。</p> <p>本质上是一个有记忆的搜索算法，搜索过程会记录见过的状态的最优解，并维护一个带有较优解的状态集合，在搜索过程中会不断更新这个集合，从一些优化的状态中进行搜索，而不是从头搜索，相比于每次都从头训练的方法，这种方法可以减少搜索的时间。值得一提的是这个状态集合包括树搜索中所有深度的可能的状态，或者所有时刻的可能的状态，即这些状态中已放置的macro的数量是不必一样的。作者在文中提供了理论证明，证明这种迭代方式能保证状态价值的提升，但似乎并没有证明其收敛性。从结果上来说，这个方法在HPWL上有很好的表现，与SOTA方法有一比高下的能力，但在拥塞度上没有过多说明，PPA的考量也没有给出。</p> <h2 id="methodology">Methodology</h2> <h3 id="monte-carlo-tree-search">Monte Carlo Tree Search</h3> <ul> <li>树搜索是从空白画布\(s_0\)开始，在每个步骤选择一个macro，将新的状态\(s_{t+1}\)添加到孩子节点中，构建一个布局搜索树。将状态\(s\)的子结点，即放置下一个macro的新状态的集合定义为\(\mathcal{C}(s)\)，经过\(s\)这一中间态得到的最终结果定义为叶子结点\(\mathcal{P}(s)\)。</li> <li>对于节点的扩展，或者说动作的选取，采用了束搜索的方法，每次扩展时都维护一个扩展列表\(\mathcal{F}\)。</li> <li>记录每个访问过的状态\(s\)的最优结果\(Q(s)=\max_{s_T\in \mathcal{P}(s)} -\text{HPWL}(s_T)\)，并且记录访问次数\(N(s)\)。</li> <li>状态空间是非常大的，所以必须要维护\(\mathcal{F}\)的大小，也就是滚动边界机制，参考UCT算法，定义状态\(s\)的score为\(S(s)=Q(s)+\frac{\alpha}{\sqrt{N(s)}}\)，每次扩展时选择score最大的状态进行扩展。</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_reading/macro_tree_search-480.webp 480w,/assets/img/paper_reading/macro_tree_search-800.webp 800w,/assets/img/paper_reading/macro_tree_search-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_reading/macro_tree_search.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="rl">RL</h3> <ul> <li>参考wiremask的视觉输入</li> <li>选择线长增量最小的贪心策略</li> <li>U-net结构，actor-critic算法</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_reading/macro_tree_RL-480.webp 480w,/assets/img/paper_reading/macro_tree_RL-800.webp 800w,/assets/img/paper_reading/macro_tree_RL-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_reading/macro_tree_RL.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="experiment">Experiment</h2>]]></content><author><name></name></author><category term="paper-reading"/><category term="chip"/><category term="RL"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Reinforcement Learning Policy as Macro Regulator Rather than Macro Placer</title><link href="https://truman0102.github.io/blog/2024/macro-regulator/" rel="alternate" type="text/html" title="Reinforcement Learning Policy as Macro Regulator Rather than Macro Placer"/><published>2024-12-11T04:00:00+00:00</published><updated>2024-12-11T04:00:00+00:00</updated><id>https://truman0102.github.io/blog/2024/macro-regulator</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/macro-regulator/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>这篇文章提出了一个在现有布局结果上重排的优化方法，聚焦的主要问题是现有方法只优化HPWL，可能会使macro靠近chip中心，远离边缘，其实是一种过拟合的不合理的现象，所以实质上是在给奖励函数打补丁。另外这篇工作在现有工具上量化了PPA性能，更贴近实际工程应用。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_reading/regulator_res-480.webp 480w,/assets/img/paper_reading/regulator_res-800.webp 800w,/assets/img/paper_reading/regulator_res-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_reading/regulator_res.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="methodology">Methodology</h2> <p>所谓的regulator其实就是度量macro距离chip边缘的距离，越靠近边缘regularity越小，优化目标就是HPWL + regularity。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_reading/regulator_overview-480.webp 480w,/assets/img/paper_reading/regulator_overview-800.webp 800w,/assets/img/paper_reading/regulator_overview-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_reading/regulator_overview.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="experiment">Experiment</h2>]]></content><author><name></name></author><category term="paper-reading"/><category term="chip"/><category term="RL"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Transferable Chip Placement via Offline Decision Transformer</title><link href="https://truman0102.github.io/blog/2024/chipformer/" rel="alternate" type="text/html" title="Transferable Chip Placement via Offline Decision Transformer"/><published>2024-12-09T16:00:00+00:00</published><updated>2024-12-09T16:00:00+00:00</updated><id>https://truman0102.github.io/blog/2024/chipformer</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/chipformer/"><![CDATA[<h2 id="introduction">Introduction</h2> <ul> <li>offline RL</li> <li>transferable placement policy</li> <li>offline data are collected from multiple chip circuits using (near) expert-level placement behaviors, differing from the common offline RL setting where the data are collected by sub-optimal behavior policies over a single environment.</li> <li>transformer placement network</li> </ul> <h2 id="methodology">Methodology</h2> <p>离线强化学习的第一个要素就是离线数据的收集，这篇工作提供了12个芯片电路任务的\(500\times 12\)<a href="https://drive.google.com/drive/folders/1F7075SvjccYk97i2UWhahN_9krBvDCmr">专家级布局结果</a>，数据量比较大，很有研究价值。</p> <h3 id="offline-rl">Offline RL</h3> <p>给定一个轨迹\(\tau=(s_1,a_1,\dots,s_T,a_T)\)，其中\(s_t\)是状态，\(a_t\)是动作，可以定义一个后视信息\(\text{HI}(\tau)\)，可以理解成一个隐式可学习特征，用于指导决策，可以是任何函数，自由度较高，在一些工作中可以是累计回报，也可以是最终状态，本文是电路的可学习的embedding。本文的训练目标是最大化条件策略</p> \[\max_{\theta}\mathbb{E}_{(c,\tau)\sim D}\left[\sum_{t=1}^{T}\log\pi_{\theta}(a_t|\tau_t,\text{HI}(c,\tau))\right]\] <p>其中\(D\)是经验轨迹数据集，\(c\)是电路，\(\tau_t\)是直到时间\(t\)的轨迹。</p> <p>电路\(c\)可以表示为无向图\(g^c\)，邻接矩阵\(A^c\in\{0,1\}^{N\times N}\)，其中\(N\)是节点数，节点特征矩阵\(X^c\in\mathbb{R}^{N\times D}\)，\(D\)是节点特征维度。参考VAE的思想，优化变分下界</p> \[\max_{\phi}\mathbb{E}_{c\sim D}\left[\mathbb{E}_{q_\phi(Z\vert X,A)}\log p(A\vert Z)-\text{KL}(q(Z\vert X,A)\Vert p(Z))\right]\] <p>其中\(q_\phi(Z\vert X,A)=\prod_{i=1}^{N}q_\phi(z_i\vert X,A)\)是来自编码器的后验分布，\(p(A\vert Z)=\prod_{i=1}^{N}\prod_{j=1}^{N}\sigma(z_i^Tz_j)\)是来自解码器的似然分布，\(Z=\left[z_1,\dots,z_N\right]^T\)是隐变量，\(p(Z)\)是高斯先验分布。可以看出，这个模型是一个图自编码器，用于学习电路的embedding，所以用节点隐变量的均值来近似替代电路的embedding\(\text{HI}(c,\tau)=\text{HI}(c)=\frac{1}{N}\sum_{i=1}^{N}z_i\)。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_reading/chipformer-480.webp 480w,/assets/img/paper_reading/chipformer-800.webp 800w,/assets/img/paper_reading/chipformer-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_reading/chipformer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>模型结构以GPT为backbone，输入包括state token和action token，以及电路的embedding，其中state token参考了MaskPlace工作，包括了position mask、wire mask和view mask三个通道，action token是二维坐标，这两个token在输入前面都有一个embedding layer进行编码。</p> <p>最后是在未见电路上的微调，优化目标与条件策略是类似的，但考虑到微调时每个轮次生成的轨迹是不同的，这些轨迹可能有好有坏，所以根据轨迹的回报对其策略进行加权，此外增加了一个策略熵的正则，以增加探索性。最终的微调目标是</p> \[\min_\theta -\mathbb{E}_{\mathcal{B(\tau)}}\left[\omega(\tau)\log_\theta(a_t\vert \tau_t,\text{HI}(c))\right] + \lambda\max(0,\beta+\mathbb{E}_{\mathcal{B(\tau)}}[\ \log_\theta(\cdot\vert s_t,\text{HI}(c))]\] <p>其中\(\omega(\tau)=\frac{\exp(R(\tau)/\alpha)}{\mathbb{E}_{\mathcal{B(\tau)}}\exp(R(\tau)/\alpha)}\)是轨迹的权重，\(R(\tau)\)是轨迹的回报，\(\alpha\)是温度参数，\(\beta\)是熵的最小值。</p> <h2 id="experiment">Experiment</h2>]]></content><author><name></name></author><category term="paper-reading"/><category term="chip"/><category term="RL"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Chip Placement with Diffusion</title><link href="https://truman0102.github.io/blog/2024/diffusion-placement/" rel="alternate" type="text/html" title="Chip Placement with Diffusion"/><published>2024-12-09T15:00:00+00:00</published><updated>2024-12-09T15:00:00+00:00</updated><id>https://truman0102.github.io/blog/2024/diffusion-placement</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/diffusion-placement/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>diffusion model for macro placement</p> <h2 id="methodology">Methodology</h2> <p>GNN and Attention</p> <h2 id="experiment">Experiment</h2>]]></content><author><name></name></author><category term="paper-reading"/><category term="chip"/><category term="RL"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Macro Placement by Wire-Mask-Guided Black-Box Optimization</title><link href="https://truman0102.github.io/blog/2024/wiremask-bbo/" rel="alternate" type="text/html" title="Macro Placement by Wire-Mask-Guided Black-Box Optimization"/><published>2024-12-09T14:00:00+00:00</published><updated>2024-12-09T14:00:00+00:00</updated><id>https://truman0102.github.io/blog/2024/wiremask-bbo</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/wiremask-bbo/"><![CDATA[<h2 id="introduction">Introduction</h2> <h2 id="background">Background</h2> <p>这篇文章的背景部分概括问题比较好，因此我直接引用了原文的内容。</p> <h3 id="macro-placement">Macro Placement</h3> <p>Macro placement的输入是网表\(H=(V,E)\)，\(V\)是所有cell的信息，\(E\)是所有的边的信息，输出是所有macro的二维坐标。</p> <p>HPWL是常用的评价指标，也可以作为RL的reward，具体来说就是\(E\)中所有边构成的矩形的半周长之和。</p> <p>拥塞度是另一个重要的指标，RUDY为常见的计算拥塞度的方法。具体计算方法为取前\(10\%\)的grid，构成一个子图\(G^{\prime}\)，然后计算\(G^{\prime}\)中每个点所属的所有超边的矩形区域的平均拥塞度\(\frac{1}{\vert G^{\prime} \vert}\sum_{g_i\in G^{\prime}}\sum_{e_j\in E(g_i)}\frac{w_j+h_j}{w_j\cdot h_j}\)。</p> <p>密度用于衡量重叠程度，由于无重叠是宏布局的硬约束，因此有些方法中不作讨论。</p> <p>面积是包围所有宏的最小矩形的面积，在一个固定面积的芯片中布局时，优化目标一般不是面积而是HPWL等。</p> <h3 id="packing-based-methods">Packing-based Methods</h3> <p>macro placement任务中，每个macro以矩形表示，在芯片内部进行放置。目前几种表示方法有sequence-pair, \(\text{B}^\prime\)树, corner block list等。</p> <p>对于marco和标准单元的放置一般采用分而治之的方法，对标准单元进行聚类，然后对marco和类团进行放置，再对类团重新分配，优化布局。聚类方法虽然能缩减任务规模，但可能会切断一些连接，妨碍找到最优解。</p> <h3 id="analytical-methods">Analytical Methods</h3> <p>Analytical methods是一种基于数学模型的方法，通过建立数学模型，求解最优解，以DREAMPlce为代表，将整个placement任务视为最小化目标函数的问题，目标函数包括平滑加权平均线长和密度。分析方法的缺点是不能保证单元之间不重叠，即不能保证硬约束。</p> <h3 id="intensive-reward-in-maskplace">Intensive Reward in MaskPlace</h3> <p>将放置macro后HPWL的增加值作为reward，提供即时奖励。</p> <h2 id="methodology">Methodology</h2> <ul> <li>对macro进行排序，依据是与其相连接的单元的面积和。</li> <li>wire-mask-guided placement: 通过计算满足硬约束位置的HPWL增量来指导macro的有序放置。</li> <li>black-box optimization <ul> <li>random search</li> <li>bayesian optimization</li> <li>evolutionary algorithm: 随机选择两个位置交换位置</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="paper-reading"/><category term="chip"/><category term="RL"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Learning Global Routing via Hub Generation and Pin-hub Connection</title><link href="https://truman0102.github.io/blog/2024/hubrouter/" rel="alternate" type="text/html" title="Learning Global Routing via Hub Generation and Pin-hub Connection"/><published>2024-12-04T19:00:00+00:00</published><updated>2024-12-04T19:00:00+00:00</updated><id>https://truman0102.github.io/blog/2024/hubrouter</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/hubrouter/"><![CDATA[<h2 id="introduciton">Introduciton</h2> <h2 id="fundamentals">Fundamentals</h2> <h3 id="rsmt">RSMT</h3> <p>Rectilinear Steiner 最小树问题（Rectilinear Steiner Minimum Tree，简称 RSMT）是一个组合优化问题，旨在通过添加额外的 Steiner 点，在二维平面上使用仅水平和垂直线段（曼哈顿距离）连接给定的一组点（称为终端点），使得连接的总线长最短。相较于最小生成树（Minimum Spanning Tree，MST）只连接终端点，RSMT 允许添加 Steiner 点，从而可能构造出总长度更短的连通网络。</p> <p>RSMT 问题在集成电路设计、网络布线等领域具有重要应用。然而，由于该问题被证明是 NP 完全问题，所以精确求解在计算上是不可行的，通常需要使用启发式算法或近似算法来获得近似解，用R-MST来近似，其时间复杂度为\(On\log n\)，长度最多为最优RSMT的\(1.5\)倍。</p> <h3 id="hub">Hub</h3> <p>Hub是网格中的一个连接点，类似于交通路段的路口，根据上下左右网格的连接情况，可以分为四种类型：</p> \[\begin{aligned} &amp;+: &amp;r_{(i-1)j} = r_{(i+1)j} = r_{i(j-1)} = r_{i(j+1)} = 1 \\ &amp;\perp: &amp;r_{(i-1)j} + r_{(i+1)j} = r_{i(j-1)} + r_{i(j+1)} = 3 \\ &amp;\llcorner: &amp;r_{(i-1)j} + r_{(i+1)j} = 1 \;\text{and}\; r_{i(j-1)} + r_{i(j+1)} = 1 \\ &amp;\cdot: &amp;r_{(i-1)j} + r_{(i+1)j} + r_{i(j-1)} + r_{i(j+1)} = 1 \\ \end{aligned}\] <p>Hub在文中所起的作用类似于Steiner点，但是Hub的生成和连接方法与RSMT有所不同。</p> <h2 id="methodology">Methodology</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_reading/HUB-480.webp 480w,/assets/img/paper_reading/HUB-800.webp 800w,/assets/img/paper_reading/HUB-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_reading/HUB.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="hub-generation">Hub Generation</h3> <p>Hub的生成使用的是条件生成模型，输出以生成Hub为主，同时还生成了用于过滤噪声点的stripe mask和未被使用的预路由路径。</p> <p>stripe是一个布尔值矩阵，可用于拒绝部分生成的错误Hub。在具体过滤时，stripe mask按行或列进行计算，如果行或列上有超过半数的mask为真，则该行或列被保留。所以stripe mask是一个部分列或行全部为真的矩阵。</p> <h3 id="pin-hub-connection">Pin-hub Connection</h3> <p>连接hub和pin被视为一个RSMT构建问题，引入hub的构建方法的好处是</p> <ol> <li>可以降低复杂度至\(O(n\log n)\)</li> <li>RSMT只能找到最短路径，引入hub可以支持其他约束条件</li> </ol> <p>具体地，参考REST<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>学习Rectilinear edge sequence (RES)的方法，应用了actor critic算法。actor根据给定的点坐标生成RES，critic预测RSMT的长度，这个预测值在训练时向真实值靠拢，以达到优化目的。</p> <h2 id="experiment">Experiment</h2> <h3 id="dataset">Dataset</h3> <p>在routing benchmark ISPD-07上应用NCTU-GR<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>获取真实的路由示例。额外引入的路由数据集包括ISPD-98、DRL-8和DRL-16.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>J. Liu, G. Chen, and E. F. Young. Rest: Constructing rectilinear steiner minimum tree via reinforcement learning. In 2021 58th ACM/IEEE Design Automation Conference (DAC), pages 1135–1140. IEEE, 2021. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>W.-H. Liu, W.-C. Kao, Y.-L. Li, and K.-Y. Chao. Nctu-gr 2.0: Multithreaded collision-aware global routing with bounded-length maze routing. IEEE Transactions on computer-aided design of integrated circuits and systems, 32(5):709–722, 2013. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="paper-reading"/><category term="chip"/><category term="RL"/><summary type="html"><![CDATA[Introduciton]]></summary></entry><entry><title type="html">The Policy-gradient Placement and Generative Routing Neural Networks for Chip Design</title><link href="https://truman0102.github.io/blog/2024/generative-routing-chip/" rel="alternate" type="text/html" title="The Policy-gradient Placement and Generative Routing Neural Networks for Chip Design"/><published>2024-12-04T17:00:00+00:00</published><updated>2024-12-04T17:00:00+00:00</updated><id>https://truman0102.github.io/blog/2024/generative-routing-chip</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/generative-routing-chip/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>这篇文章是<a href="/blog/2024/joint-learning-chip">布局学习</a>的续作，在宏放置工作的基础上，提出了混合尺寸宏放置和生成式路由方法。</p> <h2 id="fundamentals">Fundamentals</h2> <h3 id="global-routing-grid-protocol">Global Routing Grid Protocol</h3> <p>在全局路由中，物理芯片被分割成多个矩形网格，每个网格代表一个节点，相邻网格的公共边表示两个节点之间的连接，也将这个节点称作全局路由单元。所有路由都应遵循Rectilinear Steiner Tree (RST)规则，连接路径仅限于水平和垂直线段。</p> <h2 id="methodology">Methodology</h2> <h3 id="placement">Placement</h3> <p>与前一篇工作基本一致，主要有两点改进</p> <ol> <li>考虑了宏的尺寸，在采取放置动作时，选择宏的中心点并在二元矩阵中对整个宏的位置进行标记。</li> <li>在奖励函数中额外引入了对重叠的惩罚。</li> </ol> <p>Placement作为pipeline的第一阶段，与路由任务都接受布线长度作为奖励信号，这里采用了变权的长度估计方法，总结来说就是训练前期采用HPWL，训练后期采用生成模型的路由结果，这样的设计是考虑到前期的布线结果可能不够准确。</p> <h3 id="generative-routing">Generative Routing</h3> <p>输入是基于放置结果的与全局路由单元网格等大的图像，包括三个通道，分别是引脚的位置、水平和垂直网格边缘的可用性，输出是一个图像，其单元格取值表示是否属于路由的概率，对应生成式路由模型。路由生成模型是一个生成对抗网络，它包含一个基模型\(G_{\text{base}}\)和一个处理边长超过\(64\)的大模型\(G_{\text{large}}\)。\(G_{\text{base}}\)的热力图和\(G_{\text{large}}\)的热力图相加用于生成更大的路由图。</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/paper_reading/cGAN-480.webp 480w,/assets/img/paper_reading/cGAN-800.webp 800w,/assets/img/paper_reading/cGAN-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/paper_reading/cGAN.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>判别器评估路由结果的连通性和真实性，这是路由任务的主要对抗损失。此外，作者采用了focal loss去学习大量琐碎的否定点和少量的正点。考虑到HPWL可以作为路由的理论下界，可以将路由结果的长度与半周长的差值作为限制线长的正则项。</p> <h3 id="learning-net-order-to-route">Learning Net Order to Route</h3> <h2 id="experiment">Experiment</h2> <h3 id="benchmark">Benchmark</h3> <p>ISPD-2005 for placement and ISPD-07 for routing</p>]]></content><author><name></name></author><category term="paper-reading"/><category term="chip"/><category term="RL"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">On Joint Learning for Solving Placement and Routing in Chip Design</title><link href="https://truman0102.github.io/blog/2024/joint-learning-chip/" rel="alternate" type="text/html" title="On Joint Learning for Solving Placement and Routing in Chip Design"/><published>2024-12-04T15:00:00+00:00</published><updated>2024-12-04T15:00:00+00:00</updated><id>https://truman0102.github.io/blog/2024/joint-learning-chip</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/joint-learning-chip/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>布局布线任务主要由三部分组成，分别是宏单元的放置、标准单元的放置和路由，这篇文章的主要工作是提出了应用强化学习方法的宏单元放置方法，至于标准单元的放置和路由，则采用了现有的DREAMPlace和DeepPR方法。下面将围绕强化学习方法介绍主要内容。</p> <h2 id="methodology">Methodology</h2> <h3 id="state">State</h3> <p>状态分为两部分，分别是描述全局的布局图\(I\)和包含已放置宏的详细位置的网表图\(H\)，\(I\)是一个二进制矩阵，用于表示单元格是否被占用。</p> <h3 id="action">Action</h3> <p>RL agent每次可以选择一个宏单元进行放置，放置的位置由一个二维坐标\((x, y)\)表示。因此动作空间是\(I\)中所有未被占用的位置。</p> <h3 id="reward">Reward</h3> <p>奖励分为外部奖励和内部奖励，外部奖励粗略估计布局布线的质量，内部奖励用于解决稀疏奖励问题，鼓励agent进行探索。</p> <p>外部奖励由线长和拥塞组成，真实线长取决于路由结果，为了快速评估，所以用半周长线长(HPWL)代替。拥塞通过<a href="https://circuitnet.github.io/feature/routability%20features.html#rudy-%E2%91%AA--%E2%91%AE">矩形均匀线密度</a>(RUDY)计算，文中路由拥塞的阈值设为0.1。</p> \[R_E = -\text{WireLength}(P,H) - \lambda\text{Congestion}(P,H)\] <p>其中\(P\)是放置结果，\(H\)是网表图，\(\lambda\)是权重。</p> <p>内部奖励采用了随机网络蒸馏(Random Network Distillation, RND)的方法，用于解决稀疏奖励问题。RND的目标是预测随机网络的输出，奖励是预测误差。</p> \[R_I = \Vert \hat{f}_\theta(o) - f(o) \Vert^2\] <h3 id="model">Model</h3> <p>策略网络的输入是\(I\)和\(H\)，使用了一个CNN和一个GNN对状态分别进行编码，然后将两个编码结果拼接，输入到一个MLP中，输出动作的概率分布，实现了PPO算法。</p> <h3 id="pretraining">Pretraining</h3> <p>类似课程学习的思想，预训练阶段只对宏单元放置进行训练，学习一个中间位置。</p> <h2 id="experiment">Experiment</h2> <p>Benchmark选择的是ISPD-2005</p>]]></content><author><name></name></author><category term="paper-reading"/><category term="chip"/><category term="RL"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Macro Placement for Chip Design</title><link href="https://truman0102.github.io/blog/2024/macro-placement/" rel="alternate" type="text/html" title="Macro Placement for Chip Design"/><published>2024-12-03T14:30:00+00:00</published><updated>2024-12-03T14:30:00+00:00</updated><id>https://truman0102.github.io/blog/2024/macro-placement</id><content type="html" xml:base="https://truman0102.github.io/blog/2024/macro-placement/"><![CDATA[<h2 id="what-are-macros">What are macros?</h2> <p>宏是较大的功能块，例如 IC 的存储器（SRAM、ROM）、模拟设备（DAC、ADC）、时钟宏（PLL）或接口宏。在物理设计中，宏通常被放置在芯片的外围，以确保它们能够获得足够的电源和散热。</p> <h2 id="guidelines-to-place-macros">Guidelines to place macros</h2> <ol> <li>根据飞线分析来放置宏，即与某些端口或频繁通信的宏，然后将它们放置在彼此附近以减少延迟。优先顺序为宏到端口&gt;宏到宏&gt;宏到标准单元。</li> <li>宏的放置遵循分层命名约定。</li> <li>将宏放置在芯片外围，这样更容易为它们供电，避免电压下降。如果将它们放置在芯片中央，可能会导致大量绕行布线。</li> <li>保持宏之间的最小通道长度</li> <li>宏之间不应该有重叠的区域或交叉连接</li> <li>宏引脚应朝向核心区域放置。原因是宏与标准单元相连，而大多数逻辑连接都在核心区域内，因此宏引脚应朝向核心区域放置。</li> <li>避免在宏放置中出现缺口。</li> </ol> <h2 id="why-we-place-macro-before-standard-cell-in-physical-design">Why we place macro before standard cell in physical design?</h2> <p>在集成电路的物理设计流程中，将宏单元在标准单元之前放置是一个经过深思熟虑的策略，背后有着多个具体原因和考虑：</p> <ol> <li> <p><strong>占用面积大</strong>：宏单元通常包括大规模的存储器模块或专用的IP模块，这些模块在芯片上需要占据很大的面积。由于其体积庞大，一旦确定位置后，很难再进行调整。因此，在设计初期就需要为它们预留足够的空间，以避免后期设计调整带来的复杂性。</p> </li> <li> <p><strong>固定布局的约束</strong>：由于宏单元的尺寸较大，而且可能有严格的性能、热管理和电力传输要求，它们通常会受到许多布局约束。这些约束要求在设计的早期阶段予以解决，这样可以降低对后续步骤的影响。</p> </li> <li> <p><strong>供电和散热考虑</strong>：宏单元由于设计的复杂性，通常会有更高的功耗和更复杂的供电需求。先放置这些单元并进行供电布线有利于优化电源分配，同时也可以进行早期的热分析，以确保芯片的可靠性和性能。</p> </li> <li> <p><strong>信号完整性和时序优化</strong>：宏单元可能会引入较长的信号路径，它们的相对位置将会直接影响到信号的延迟和完整性。在早期进行放置，能够更好地规划总线和关键信号路径，避免后期的重布局或时序问题。</p> </li> <li> <p><strong>设计的灵活性</strong>：通过首先确定宏单元的位置，可以在更紧凑和高效的空间中安排标准单元。这种方法允许对标准单元的布局进行更灵活的优化，同时避免对宏单元的重新排列造成的复杂调整。</p> </li> <li> <p><strong>提高设计效率</strong>：宏单元的早期放置和固定，使后续的设计流程更加流畅。当宏单元位置确定后，物理设计中的后续步骤（例如标准单元的放置、详细布线及优化等）可以在一个较为稳定的框架下进行，减少了因宏单元位置变化带来的不确定性。</p> </li> </ol> <p>通过在物理设计流程的初期阶段优先考虑宏单元的位置和布局，不仅可以确保设计满足技术和性能的要求，还能大幅提高整个设计流程的效率和效果。</p>]]></content><author><name></name></author><category term="chip-design"/><category term="chip"/><category term="EDA"/><summary type="html"><![CDATA[brief introduction to macro placement in chip design]]></summary></entry></feed>